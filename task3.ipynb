{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logisticRegression import LogisticRegression, Optimizer\n",
    "from scipy.io.arff import loadarff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addInteractions(X):\n",
    "    newX=X\n",
    "    for i in range(X.shape[1]):\n",
    "        for j in range(i+1,X.shape[1]):\n",
    "            newX=np.c_[newX,np.multiply(X[:,i],X[:,j])]\n",
    "    return newX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Add a stopping rule\n",
    "2. Perform tests for max 500 iterations (unless it converges earlier), use balanced accuracy (so do some train test splits, at least 5)\n",
    "3. Check how the log likelihood value depends on iterations for each algorithm for train data\n",
    "4. Compare the algorithms with 4 other existing solutions such as: LDA (Linear Discriminant analysis), QDA (Quadratic\n",
    "Discriminant Analysis), Decision tree and Random Forest\n",
    "5. In the case of small datasets, please compare the two versions of the logistic regression: model\n",
    "without interactions and model with interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Stopping rule: If the differences in loss function are smaller than 0.0001, stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just an overall idea, feel free to delete it all or modify or whatever :)\n",
    "# I'm wondering if this way of keeping results is optimal for later generating graphs from them\n",
    "# Currently it's just the result, name of the classifier, and split, seed\n",
    "# hmm cause for the accuracies we will probably want to draw boxplots, so like on the y axis accuracy, on the x axis train test split and then for each train test split a boxplot for each type of classifier\n",
    "# I guess it should be possible with sns, maybe by setting y to accuracy, x to split and hue by classifier type or smth like that\n",
    "# For the plots of loss function, I'm not sure how to represent it, whether to compute the mean for each iteration and plot a line going through those points\n",
    "# or to just take a single result and plot that\n",
    "def performExperiment(X,y,logisticparams):\n",
    "    costs=[]\n",
    "    accuracies=[]\n",
    "    splits = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "    seeds = [42,123,0,321,9]\n",
    "    classifiersNames = ['Linear Discriminant Analysis','Quadratic Discriminant Analysis', 'Decision Tree Classifier', 'Random Forest Classifier']\n",
    "    classifiers = [LinearDiscriminantAnalysis(),QuadraticDiscriminantAnalysis(),DecisionTreeClassifier(random_state=seed),RandomForestClassifier(random_state=seed)]\n",
    "    for split in splits:\n",
    "        for seed in seeds:\n",
    "            np.random.seed(seed)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split, random_state=seed)\n",
    "\n",
    "            for logisticparam in len(logisticparams):\n",
    "                logisticRegressor = LogisticRegression(learningRate=logisticparam.learningRate,noOfIterations=500, optimizer=logisticparam.optimizer)\n",
    "                costs = logisticRegressor.fit(X_train.astype(float),y_train.astype(float))\n",
    "                y_pred=logisticRegressor.predict(X_test)\n",
    "                costs.append([costs,logisticparam.optimizer,seed,split])\n",
    "                accuracies.append([1-np.sum(np.abs(y_pred-y_test))/len(y_test),logisticparam.optimizer,seed,split])\n",
    "\n",
    "            for i,classifier in enumerate(classifiers):\n",
    "                costs = classifier.fit(X_train.astype(float),y_train.astype(float))\n",
    "                y_pred=classifier.predict(X_test)\n",
    "                costs.append([costs, classifiersNames[i],seed,split])\n",
    "                accuracies.append([1-np.sum(np.abs(y_pred-y_test))/len(y_test),classifiersNames[i],seed,split])\n",
    "    # We could then produce some graphs and means from those results\n",
    "    return costs, accuracies\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
