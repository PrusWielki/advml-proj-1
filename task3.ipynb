{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logisticRegression import LogisticRegression, Optimizer\n",
    "from scipy.io.arff import loadarff\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addInteractions(X):\n",
    "    newX=X\n",
    "    for i in range(X.shape[1]):\n",
    "        for j in range(i+1,X.shape[1]):\n",
    "            newX=np.c_[newX,np.multiply(X[:,i],X[:,j])]\n",
    "    return newX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Add a stopping rule\n",
    "2. Perform tests for max 500 iterations (unless it converges earlier), use balanced accuracy (so do some train test splits, at least 5)\n",
    "3. Check how the log likelihood value depends on iterations for each algorithm for train data\n",
    "4. Compare the algorithms with 4 other existing solutions such as: LDA (Linear Discriminant analysis), QDA (Quadratic\n",
    "Discriminant Analysis), Decision tree and Random Forest\n",
    "5. In the case of small datasets, please compare the two versions of the logistic regression: model\n",
    "without interactions and model with interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Stopping rule: If the differences in loss function are smaller than 0.0001, stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
